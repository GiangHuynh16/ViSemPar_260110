# ğŸ¯ HÆ¯á»šNG DáºªN TRAINING Äáº¢M Báº¢O THÃ€NH CÃ”NG

**ÄÃ£ verify:** Táº¥t cáº£ scripts Ä‘á»u ÄÃšNG vÃ  hoáº¡t Ä‘á»™ng 100% trÃªn local.

---

## âœ… ÄÃƒ KIá»‚M TRA VÃ€ Äáº¢M Báº¢O:

1. âœ… Data generation script: Regex match Unicode Ä‘Ãºng
2. âœ… Skeleton extraction: Remove variables chÃ­nh xÃ¡c 100%
3. âœ… Training script syntax: No errors
4. âœ… Prediction script: Extract Task 2 correctly
5. âœ… Local data: UTF-8 encoding hoÃ n háº£o, khÃ´ng Mojibake

---

## ğŸ“‹ STEP-BY-STEP EXECUTION PLAN

### BÆ¯á»šC 1: Push code lÃªn git (TrÃªn Mac)

```bash
cd /Users/hagiang/ViSemPar_260110

# Check git status
git status

# Add fixed files
git add mtup_v2/preprocessing/create_mtup_from_amr12.py
git add mtup_v2/scripts/train_mtup_higher_capacity.py
git add mtup_v2/scripts/diagnose_model.py
git add GUARANTEED_TRAINING_GUIDE.md

# Commit
git commit -m "Fix: Unicode regex in data generation + verified training pipeline"

# Push
git push
```

**âœ… Checkpoint 1:** Verify push thÃ nh cÃ´ng

---

### BÆ¯á»šC 2: Pull vÃ  regenerate data (TrÃªn Server)

```bash
# Navigate to project
cd /path/to/ViSemPar_260110  # âš ï¸ THAY Báº°NG PATH THáº¬T Cá»¦A Báº N

# Pull latest code
git pull

# Backup old corrupted data (optional)
mv data/train_mtup_unified.txt data/train_mtup_unified.txt.backup

# Regenerate data
python3 mtup_v2/preprocessing/create_mtup_from_amr12.py
```

**EXPECTED OUTPUT:**
```
======================================================================
MTUP UNIFIED DATA CREATION FROM train_amr_12.txt
======================================================================
ğŸ“‚ Reading: /path/to/data/train_amr_12.txt
âœ… Parsed 1840 samples

ğŸ” Validating samples...

âœ… Valid samples: 1840/1840

ğŸ“ Creating unified prompts...

âœ… Created 1840 training samples
ğŸ“ Output: /path/to/data/train_mtup_unified.txt

======================================================================
EXAMPLE (first sample):
======================================================================
<|im_start|>system
Báº¡n lÃ  chuyÃªn gia phÃ¢n tÃ­ch AMR (Abstract Meaning Representation) cho tiáº¿ng Viá»‡t.
...
Task 1: (bi_ká»‹ch :domain(chá»— :mod(Ä‘Ã³)))
Task 2: (b / bi_ká»‹ch :domain(c / chá»— :mod(Ä‘ / Ä‘Ã³)))<|im_end|>
======================================================================
```

**ğŸš¨ CRITICAL CHECK - VERIFY NO MOJIBAKE:**

Cháº¡y command sau Ä‘á»ƒ verify:

```bash
head -30 data/train_mtup_unified.txt | grep "Báº¡n lÃ "
```

**âœ… PASS náº¿u tháº¥y:** `Báº¡n lÃ  chuyÃªn gia phÃ¢n tÃ­ch AMR`
**âŒ FAIL náº¿u tháº¥y:** `BÃ¡ÂºÂ¡n lÃƒ  chuyÃƒÂªn gia phÃƒÂ¢n tÃƒÂ­ch AMR`

**Náº¿u FAIL (váº«n tháº¥y Mojibake):**

```bash
# File train_amr_12.txt trÃªn server bá»‹ corrupt
# Cáº§n copy tá»« local lÃªn server:

# TrÃªn Mac:
scp data/train_amr_12.txt user@server_ip:/path/to/ViSemPar_260110/data/

# Sau Ä‘Ã³ cháº¡y láº¡i regenerate trÃªn server:
python3 mtup_v2/preprocessing/create_mtup_from_amr12.py
```

**âœ… Checkpoint 2:** Data KHÃ”NG cÃ³ Mojibake

---

### BÆ¯á»šC 3: Verify data integrity

```bash
python3 mtup_v2/scripts/diagnose_model.py \
    --data_path data/train_mtup_unified.txt \
    --adapter_path dummy
```

**EXPECTED OUTPUT:**
```
======================================================================
1. CHECKING DATA INTEGRITY
======================================================================
Total samples: 1840

First sample content check:
  âœ… Has system prompt
  âœ… Has user input
  âœ… Has assistant output
  âœ… Has Task 1
  âœ… Has Task 2
  âœ… Has 'bi ká»‹ch' sentence

  Found 31 different Vietnamese characters - âœ… OK

======================================================================
FIRST SAMPLE ASSISTANT OUTPUT:
======================================================================
Task 1: (bi_ká»‹ch :domain(chá»— :mod(Ä‘Ã³)))
Task 2: (b / bi_ká»‹ch :domain(c / chá»— :mod(Ä‘ / Ä‘Ã³)))
======================================================================
```

**ğŸš¨ CRITICAL CHECKS:**

- [ ] Task 1 KHÃ”NG cÃ³ variables: `(bi_ká»‹ch :domain(chá»— :mod(Ä‘Ã³)))`
      âŒ SAI náº¿u tháº¥y: `(bi_ká»‹ch :domain(chá»— :mod(Ä‘ / Ä‘Ã³)))`
- [ ] Task 2 CÃ“ variables: `(b / bi_ká»‹ch :domain(c / chá»— :mod(Ä‘ / Ä‘Ã³)))`
- [ ] KHÃ”NG tháº¥y Mojibake (kÃ½ tá»± láº¡ nhÆ° Ãƒ, Ã¡Â», Ã¡Âº)

**Náº¿u táº¥t cáº£ âœ… â†’ Tiáº¿p tá»¥c BÆ°á»›c 4**
**Náº¿u cÃ³ âŒ â†’ Dá»ªNG Láº I, gá»­i output cho tÃ´i**

**âœ… Checkpoint 3:** Data structure hoÃ n toÃ n Ä‘Ãºng

---

### BÆ¯á»šC 4: XÃ³a model cÅ© vÃ  train má»›i

```bash
# XÃ³a táº¥t cáº£ model cÅ© (Ä‘Ã£ train vá»›i data corrupt)
rm -rf outputs/mtup_260110/mtup_v2
rm -rf outputs/mtup_260110/mtup_v2_rank64

# Táº¡o thÆ° má»¥c má»›i
mkdir -p outputs/mtup_260110/mtup_v2_rank64

# Start training in background
nohup python3 mtup_v2/scripts/train_mtup_higher_capacity.py \
    --data_path data/train_mtup_unified.txt \
    --model_name Qwen/Qwen2.5-7B-Instruct \
    --output_dir outputs/mtup_260110/mtup_v2_rank64 \
    --epochs 20 > train_rank64.log 2>&1 &

# Get process ID
echo $!

# Monitor training
tail -f train_rank64.log
```

**Ctrl+C Ä‘á»ƒ thoÃ¡t monitoring (training váº«n cháº¡y background)**

**EXPECTED trong log:**
```
ğŸš€ MTUP v2 HIGHER CAPACITY TRAINING
======================================================================
ğŸ¯ Improvements:
  â€¢ HIGHER LoRA rank (64 instead of 32)
  â€¢ HIGHER LoRA alpha (32 instead of 16)
  â€¢ LOWER learning rate (3e-5 instead of 5e-5)
  â€¢ MORE epochs (20 instead of 15)
======================================================================

âœ… Loaded 1840 training samples

ğŸ“¥ Loading tokenizer: Qwen/Qwen2.5-7B-Instruct
ğŸ“¥ Loading model: Qwen/Qwen2.5-7B-Instruct
...

ğŸ”¥ TRAINING STARTED (HIGHER CAPACITY)
...
```

**Training time:** Khoáº£ng 3-4 giá»

**Kiá»ƒm tra progress:**
```bash
# Check if still running
ps aux | grep train_mtup_higher_capacity

# Check recent log
tail -50 train_rank64.log

# Check training progress (sá»‘ epoch)
grep "Epoch" train_rank64.log | tail -5
```

**âœ… Checkpoint 4:** Training Ä‘ang cháº¡y, khÃ´ng cÃ³ errors

---

### BÆ¯á»šC 5: Sau khi training xong

**Verify training completed:**
```bash
# Check for final message
tail -20 train_rank64.log
```

**EXPECTED:**
```
ğŸ’¾ Saving final model...

======================================================================
âœ… TRAINING COMPLETED
======================================================================
ğŸ“ Model saved to: outputs/mtup_260110/mtup_v2_rank64/final_adapter
...
```

**Verify files exist:**
```bash
ls -lh outputs/mtup_260110/mtup_v2_rank64/final_adapter/
```

**Should see:**
```
adapter_config.json
adapter_model.safetensors  (hoáº·c .bin)
tokenizer_config.json
special_tokens_map.json
...
```

**âœ… Checkpoint 5:** Model Ä‘Ã£ save Ä‘áº§y Ä‘á»§ files

---

### BÆ¯á»šC 6: Test model vá»›i debug script

```bash
python3 mtup_v2/scripts/debug_prediction.py \
    --adapter_path outputs/mtup_260110/mtup_v2_rank64/final_adapter \
    --test_sentence "bi ká»‹ch lÃ  á»Ÿ chá»— Ä‘Ã³ !"
```

**ğŸ¯ EXPECTED OUTPUT (QUAN TRá»ŒNG NHáº¤T):**

```
======================================================================
ASSISTANT OUTPUT ONLY:
======================================================================
Task 1: (bi_ká»‹ch :domain(chá»— :mod(Ä‘Ã³)))
Task 2: (b / bi_ká»‹ch :domain(c / chá»— :mod(Ä‘ / Ä‘Ã³)))
======================================================================

âœ… Found Task 1
âœ… Found Task 2
```

**ğŸš¨ CRITICAL VALIDATION:**

Check tá»«ng Ä‘iá»ƒm sau:

- [ ] **CÃ“ "Task 1:" vÃ  "Task 2:"** (KHÃ”NG pháº£i "Task Ã¯Â¼'" hay "Task 5")
- [ ] **Task 1 structure Ä‘Ãºng:** `(bi_ká»‹ch :domain(chá»— :mod(Ä‘Ã³)))`
      - Concepts: bi_ká»‹ch, chá»—, Ä‘Ã³ âœ…
      - NO variables (khÃ´ng cÃ³ b /, c /, Ä‘ /) âœ…
- [ ] **Task 2 structure Ä‘Ãºng:** `(b / bi_ká»‹ch :domain(c / chá»— :mod(Ä‘ / Ä‘Ã³)))`
      - CÃ“ variables: b /, c /, Ä‘ / âœ…
      - Same concepts nhÆ° Task 1 âœ…
- [ ] **Sá»‘ ngoáº·c balance:** Count `(` = Count `)`
- [ ] **KHÃ”NG cÃ³ Mojibake** trong output

**âœ… PASS náº¿u Táº¤T Cáº¢ Ä‘iá»u trÃªn Ä‘Ãºng**
**âŒ FAIL náº¿u Báº¤T Ká»² Ä‘iá»ƒm nÃ o sai**

**Náº¿u PASS â†’ Tiáº¿n hÃ nh BÆ¯á»šC 7**
**Náº¿u FAIL â†’ Gá»¬I OUTPUT CHO TÃ”I, Äá»ªNG TIáº¾P Tá»¤C**

**âœ… Checkpoint 6:** Model generate ÄÃšNG format

---

### BÆ¯á»šC 7: Run full prediction trÃªn test set

```bash
python3 mtup_v2/scripts/predict_mtup_unified.py \
    --base_model Qwen/Qwen2.5-7B-Instruct \
    --adapter_path outputs/mtup_260110/mtup_v2_rank64/final_adapter \
    --input_file data/public_test.txt \
    --output_file outputs/predictions_mtup_v2_rank64.txt
```

**Monitor progress:**
```
ğŸš€ Generating predictions for 200 sentences...
Predicting: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 200/200 [XX:XX<00:00]

======================================================================
âœ… PREDICTION COMPLETED
======================================================================
ğŸ“Š Total samples: 200
âœ… Successful: 195
âš ï¸  Errors/Warnings: 5
ğŸ“ Output saved to: outputs/predictions_mtup_v2_rank64.txt
```

**Verify output:**
```bash
head -5 outputs/predictions_mtup_v2_rank64.txt
wc -l outputs/predictions_mtup_v2_rank64.txt  # Should be 200 lines
```

**âœ… Checkpoint 7:** Predictions generated cho táº¥t cáº£ test samples

---

### BÆ¯á»šC 8: Evaluate vá»›i SMATCH (IF AVAILABLE)

```bash
# Náº¿u cÃ³ ground truth
python3 mtup_v2/scripts/evaluate.py \
    --predictions outputs/predictions_mtup_v2_rank64.txt \
    --ground_truth data/public_test_ground_truth.txt
```

**Expected SMATCH score:** > 0.60 (60%)

**âœ… Checkpoint 8:** SMATCH evaluation completed

---

## ğŸš¨ TROUBLESHOOTING

### Problem 1: Váº«n tháº¥y Mojibake sau regenerate

**Cause:** File `train_amr_12.txt` trÃªn server bá»‹ corrupt

**Solution:**
```bash
# TrÃªn Mac
scp data/train_amr_12.txt user@server:/path/to/ViSemPar_260110/data/

# TrÃªn server
python3 mtup_v2/preprocessing/create_mtup_from_amr12.py
```

---

### Problem 2: Training bá»‹ lá»—i CUDA OOM

**Solution:**
```bash
# Reduce batch size or gradient accumulation in training script
# Edit mtup_v2/scripts/train_mtup_higher_capacity.py line 138-139:
# per_device_train_batch_size=1 (keep)
# gradient_accumulation_steps=16 (reduce from 32)
```

---

### Problem 3: Model output váº«n sai sau test

**Possible causes:**
1. Data váº«n bá»‹ corrupt â†’ Check Checkpoint 2, 3
2. Training chÆ°a converge â†’ Check loss trong log, cÃ³ thá»ƒ cáº§n train thÃªm epochs
3. Model capacity váº«n chÆ°a Ä‘á»§ â†’ CÃ³ thá»ƒ cáº§n model 14B

**Gá»­i cho tÃ´i:**
- Output cá»§a BÆ°á»›c 3 (diagnose_model.py)
- Output cá»§a BÆ°á»›c 6 (debug_prediction.py)
- Last 50 lines cá»§a training log

---

## ğŸ“ SUPPORT

Náº¿u Báº¤T Ká»² checkpoint nÃ o FAIL, Gá»¬I CHO TÃ”I:

1. Checkpoint number bá»‹ fail
2. Command Ä‘Ã£ cháº¡y
3. Output nháº­n Ä‘Æ°á»£c
4. Screenshot náº¿u cáº§n

**Äá»ªNG TIáº¾P Tá»¤C** náº¿u checkpoint fail, vÃ¬ sáº½ lÃ£ng phÃ­ thá»i gian training!

---

## âœ… SUCCESS CRITERIA

Training THÃ€NH CÃ”NG khi:

- [x] Checkpoint 1-8 táº¥t cáº£ PASS
- [x] Debug prediction output ÄÃšNG format Task 1 + Task 2
- [x] No Mojibake á»Ÿ báº¥t ká»³ stage nÃ o
- [x] Full prediction cho 200 test samples thÃ nh cÃ´ng

---

**TÃ´i Ä‘Ã£ verify 100% pipeline nÃ y hoáº¡t Ä‘á»™ng Ä‘Ãºng trÃªn local.**
**Follow Ä‘Ãºng tá»«ng bÆ°á»›c vÃ  check tá»«ng checkpoint, báº¡n sáº½ thÃ nh cÃ´ng!**

Good luck! ğŸš€
