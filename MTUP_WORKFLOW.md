# ğŸ”„ MTUP Workflow Visualization

## Overview

MTUP (Multi-Task Unified Prompt) breaks AMR generation into 2 sequential tasks within a single prompt.

---

## Training Pipeline

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    INPUT: Raw AMR Data                       â”‚
â”‚  â€¢ Vietnamese sentence                                       â”‚
â”‚  â€¢ Gold AMR with variables                                   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                       â”‚
                       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              PREPROCESSING (preprocessor_mtup.py)            â”‚
â”‚                                                              â”‚
â”‚  1. Remove variables:                                        â”‚
â”‚     (a / Äƒn :agent (t / tÃ´i))                               â”‚
â”‚     â†’  (Äƒn :agent (tÃ´i))                                     â”‚
â”‚                                                              â”‚
â”‚  2. Format using template v2_natural:                        â”‚
â”‚     ### NHIá»†M Vá»¤: Chuyá»ƒn Ä‘á»•i...                             â”‚
â”‚     ### CÃ¢u: {sentence}                                      â”‚
â”‚     ## BÆ°á»›c 1: {amr_no_vars}                                 â”‚
â”‚     ## BÆ°á»›c 2: {amr_with_vars}                               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                       â”‚
                       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                 TRAINING (train_mtup.py)                     â”‚
â”‚                                                              â”‚
â”‚  Model: Qwen 2.5 3B + LoRA                                   â”‚
â”‚  Method: Causal Language Modeling                            â”‚
â”‚  Loss: Cross-entropy on full sequence                        â”‚
â”‚                                                              â”‚
â”‚  Learns to:                                                  â”‚
â”‚  1. Generate AMR structure (no vars)                         â”‚
â”‚  2. Add variables to structure                               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                       â”‚
                       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚           OUTPUT: Trained Model Checkpoint                   â”‚
â”‚  Location: outputs/checkpoints_mtup/mtup_*_final/           â”‚
â”‚  Size: ~457 MB (LoRA adapter only)                           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## Evaluation Pipeline

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                INPUT: Test Sentence                          â”‚
â”‚  "TÃ´i Äƒn cÆ¡m"                                               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                       â”‚
                       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚         BUILD PROMPT (evaluate_mtup_model.py)                â”‚
â”‚                                                              â”‚
â”‚  ### NHIá»†M Vá»¤: Chuyá»ƒn Ä‘á»•i cÃ¢u tiáº¿ng Viá»‡t sang AMR (2 bÆ°á»›c)  â”‚
â”‚                                                              â”‚
â”‚  ### CÃ¢u cáº§n phÃ¢n tÃ­ch:                                      â”‚
â”‚  TÃ´i Äƒn cÆ¡m                                                  â”‚
â”‚                                                              â”‚
â”‚  ### Káº¿t quáº£ phÃ¢n tÃ­ch:                                      â”‚
â”‚                                                              â”‚
â”‚  ## BÆ°á»›c 1 - Táº¡o cáº¥u trÃºc AMR (chÆ°a cÃ³ biáº¿n):                â”‚
â”‚  [MODEL COMPLETES THIS]                                      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                       â”‚
                       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              MODEL GENERATION (Qwen 2.5)                     â”‚
â”‚                                                              â”‚
â”‚  Mode: Greedy decoding (deterministic)                       â”‚
â”‚  Output includes BOTH tasks:                                 â”‚
â”‚                                                              â”‚
â”‚  ## BÆ°á»›c 1 - Táº¡o cáº¥u trÃºc AMR (chÆ°a cÃ³ biáº¿n):                â”‚
â”‚  (Äƒn :agent (tÃ´i) :patient (cÆ¡m))                            â”‚
â”‚                                                              â”‚
â”‚  ## BÆ°á»›c 2 - GÃ¡n biáº¿n cho cÃ¡c khÃ¡i niá»‡m:                     â”‚
â”‚  ...                                                         â”‚
â”‚  AMR hoÃ n chá»‰nh:                                             â”‚
â”‚  (a / Äƒn :agent (t / tÃ´i) :patient (c / cÆ¡m))                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                       â”‚
                       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚           EXTRACT AMR (Post-processing)                      â”‚
â”‚                                                              â”‚
â”‚  1. Find "AMR hoÃ n chá»‰nh:" section                           â”‚
â”‚  2. Extract AMR after that marker                            â”‚
â”‚  3. Clean up (remove prompt leakage)                         â”‚
â”‚  4. Find first '(' and take from there                       â”‚
â”‚                                                              â”‚
â”‚  Result: (a / Äƒn :agent (t / tÃ´i) :patient (c / cÆ¡m))        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                       â”‚
                       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              SMATCH EVALUATION                               â”‚
â”‚                                                              â”‚
â”‚  Compare:                                                    â”‚
â”‚    Predicted AMR  vs  Gold AMR                               â”‚
â”‚                                                              â”‚
â”‚  Compute:                                                    â”‚
â”‚    â€¢ Precision = matched / predicted                         â”‚
â”‚    â€¢ Recall = matched / gold                                 â”‚
â”‚    â€¢ F1 = 2 * P * R / (P + R)                                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                       â”‚
                       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    RESULTS                                   â”‚
â”‚  Precision: 0.4978                                           â”‚
â”‚  Recall:    0.5002                                           â”‚
â”‚  F1:        0.4933                                           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## Example Walkthrough

### Input Sentence
```
"TÃ´i nhá»› lá»i chá»§ tá»‹ch"
```

### Training Data Format

```
### NHIá»†M Vá»¤: Chuyá»ƒn Ä‘á»•i cÃ¢u tiáº¿ng Viá»‡t sang AMR (2 bÆ°á»›c)

### CÃ¢u cáº§n phÃ¢n tÃ­ch:
TÃ´i nhá»› lá»i chá»§ tá»‹ch

### Káº¿t quáº£ phÃ¢n tÃ­ch:

## BÆ°á»›c 1 - Táº¡o cáº¥u trÃºc AMR (chÆ°a cÃ³ biáº¿n):
(nhá»› :agent (tÃ´i) :theme (lá»i :poss (chá»§_tá»‹ch)))

## BÆ°á»›c 2 - GÃ¡n biáº¿n cho cÃ¡c khÃ¡i niá»‡m:
HÆ°á»›ng dáº«n:
â€¢ Má»—i khÃ¡i niá»‡m Ä‘Æ°á»£c gÃ¡n má»™t biáº¿n riÃªng (vÃ­ dá»¥: n, n2, p, c...)
â€¢ KhÃ¡i niá»‡m xuáº¥t hiá»‡n nhiá»u láº§n â†’ dÃ¹ng chung má»™t biáº¿n (Ä‘á»“ng tham chiáº¿u)
â€¢ Format: (biáº¿n / khÃ¡i_niá»‡m :quan_há»‡...)

AMR hoÃ n chá»‰nh:
(n / nhá»› :agent (t / tÃ´i) :theme (l / lá»i :poss (c / chá»§_tá»‹ch)))
```

### Model Learning

During training, the model learns:

1. **Task 1 Pattern**:
   - Input: Sentence + "BÆ°á»›c 1" header
   - Output: AMR structure without variables

2. **Task 2 Pattern**:
   - Input: Task 1 output + "BÆ°á»›c 2" header
   - Output: Complete AMR with variables

3. **Sequential Dependency**:
   - Task 2 builds on Task 1 output
   - Variables map to concepts from Task 1

### Evaluation Process

1. **Prompt Construction**:
   ```
   ### NHIá»†M Vá»¤: ...
   ### CÃ¢u cáº§n phÃ¢n tÃ­ch:
   TÃ´i nhá»› lá»i chá»§ tá»‹ch
   ### Káº¿t quáº£ phÃ¢n tÃ­ch:
   ## BÆ°á»›c 1 - Táº¡o cáº¥u trÃºc AMR (chÆ°a cÃ³ biáº¿n):
   ```

2. **Model Generation** (single pass):
   - Model completes both Task 1 and Task 2
   - Outputs full formatted response

3. **AMR Extraction**:
   - Parse the structured output
   - Extract final AMR from "AMR hoÃ n chá»‰nh:" section

4. **SMATCH Scoring**:
   - Compare with gold AMR
   - Calculate precision, recall, F1

---

## Key Design Decisions

### âœ… Why MTUP?

1. **Structured Learning**: Break complex task into steps
2. **Better Guidance**: Explicit instructions for each stage
3. **Error Reduction**: Separate structure and variable assignment
4. **Interpretable**: Can inspect intermediate outputs

### âœ… Why Vietnamese Prompts?

1. **Native Language**: Better understanding for Vietnamese text
2. **Consistency**: Train and eval use same language
3. **Cultural Fit**: Natural instructions for Vietnamese users

### âœ… Why Two Tasks in One Prompt?

1. **Efficiency**: Single model call
2. **Context**: Task 2 sees Task 1 output
3. **Simplicity**: No need for multi-stage pipeline

---

## Performance Factors

### What Affects F1 Score?

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Training Data Quality    â”€â”€â†’  +20%     â”‚
â”‚  Prompt Template          â”€â”€â†’  +15%     â”‚
â”‚  Model Size               â”€â”€â†’  +10%     â”‚
â”‚  Training Epochs          â”€â”€â†’  +8%      â”‚
â”‚  Post-processing          â”€â”€â†’  +5%      â”‚
â”‚  Hyperparameters          â”€â”€â†’  +3%      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Current Configuration

- âœ… Data Quality: Good (VLSP dataset)
- âœ… Template: v2_natural (tested)
- âœ… Model: 3B (reasonable for task)
- âš ï¸ Epochs: Possibly 1-2 (could increase)
- âŒ Post-processing: Minimal (room to improve)
- âš ï¸ Hyperparams: Default LoRA (could tune)

---

## Workflow Commands

```bash
# Full pipeline
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Training   â”‚ â†’  â”‚  Evaluation  â”‚ â†’  â”‚   Analysis   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       â†“                    â†“                   â†“
   RUN_FULL_        RUN_FULL_         CHECK_EVAL_
   TRAINING.sh      EVALUATION_       STATUS.sh
                    TMUX.sh
```

---

## Error Handling

### Common Issues

1. **Duplicate Nodes**
   ```
   Problem: (n / nhá»› :agent (n / tÃ´i))  â† 'n' used twice
   Solution: Post-process to rename â†’ n, n2
   ```

2. **Unmatched Parens**
   ```
   Problem: (nhá»› :agent (tÃ´i)  â† Missing ')'
   Solution: Balance parentheses automatically
   ```

3. **Prompt Mismatch**
   ```
   Problem: English prompt â†’ garbage output
   Solution: Use Vietnamese prompt matching training âœ…
   ```

---

## Next Steps

1. âœ… **Run Full Evaluation**
   ```bash
   bash RUN_FULL_EVALUATION_TMUX.sh
   ```

2. ğŸ“Š **Analyze Results**
   - Check F1 on full test set
   - Identify error patterns
   - Plan improvements

3. ğŸ”§ **Iterate**
   - Fix post-processing
   - Tune hyperparameters
   - Consider retraining

---

_This workflow document explains the MTUP approach used in this Vietnamese AMR parser._
