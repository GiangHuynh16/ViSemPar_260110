# Pipeline Thá»‘ng Nháº¥t - Vietnamese AMR Parser

## ğŸ¯ Má»¥c TiÃªu So SÃ¡nh

So sÃ¡nh **2 phÆ°Æ¡ng phÃ¡p** vá»›i cÃ¹ng model Ä‘á»ƒ Ä‘Ã¡nh giÃ¡ hiá»‡u quáº£ cá»§a MTUP:

| Aspect | Baseline | MTUP (Ours) |
|--------|----------|-------------|
| **Model** | Qwen 2.5 7B | Qwen 2.5 7B |
| **Approach** | Direct generation (1 task) | Two-task decomposition |
| **Template** | Simple prompt | Structured 2-step prompt |
| **Post-processing** | âŒ None (end-to-end LLM) | âŒ None (end-to-end LLM) |
| **Philosophy** | LLM learns directly | LLM learns via task decomposition |

## ğŸ“Š Current Issues to Fix

### 1. Model Inconsistency âŒ
- **Baseline**: Qwen 2.5 14B (`config/config.py` line 20)
- **MTUP**: Qwen 2.5 3B (`config/config_mtup.py` line 42)
- **Fix**: Both use **Qwen 2.5 7B**

### 2. Post-processing âŒ
- **Current**: Conservative post-processing in `evaluate_mtup_model.py`
- **Philosophy**: MTUP should be **end-to-end LLM**, not relying on post-processing
- **Fix**: Remove all post-processing

### 3. Template Formatting Issues âŒ
**Current template** (`v2_natural` in `prompt_templates.py` line 34-51):

```python
MTUP_TEMPLATE_V2_NATURAL = """### NHIá»†M Vá»¤: Chuyá»ƒn Ä‘á»•i cÃ¢u tiáº¿ng Viá»‡t sang AMR (2 bÆ°á»›c)

### CÃ¢u cáº§n phÃ¢n tÃ­ch:
{sentence}

### Káº¿t quáº£ phÃ¢n tÃ­ch:

## BÆ°á»›c 1 - Táº¡o cáº¥u trÃºc AMR (chÆ°a cÃ³ biáº¿n):
{amr_no_vars}

## BÆ°á»›c 2 - GÃ¡n biáº¿n cho cÃ¡c khÃ¡i niá»‡m:
HÆ°á»›ng dáº«n:
â€¢ Má»—i khÃ¡i niá»‡m Ä‘Æ°á»£c gÃ¡n má»™t biáº¿n riÃªng (vÃ­ dá»¥: n, n2, p, c...)
â€¢ KhÃ¡i niá»‡m xuáº¥t hiá»‡n nhiá»u láº§n â†’ dÃ¹ng chung má»™t biáº¿n (Ä‘á»“ng tham chiáº¿u)
â€¢ Format: (biáº¿n / khÃ¡i_niá»‡m :quan_há»‡...)

AMR hoÃ n chá»‰nh:
{amr_with_vars}"""
```

**Problems**:
- âŒ Mixed markdown levels (`###` vs `##`)
- âŒ Inconsistent spacing after colons
- âŒ "HÆ°á»›ng dáº«n:" and "AMR hoÃ n chá»‰nh:" on same line (should be separated)
- âŒ Free text makes parsing harder
- âŒ Not structured like JSON (harder for model to learn boundaries)

**Impact on errors**:
- Unmatched parens likely caused by unclear boundaries
- Model confused about where output starts/ends
- Free text "HÆ°á»›ng dáº«n..." may leak into output

## ğŸ”§ Fixes to Implement

### Fix 1: Unify Models to Qwen 2.5 7B

**File**: `config/config.py` (Baseline)
```python
# Line 20: Change from
MODEL_NAME = "Qwen/Qwen2.5-14B-Instruct"

# To:
MODEL_NAME = "Qwen/Qwen2.5-7B-Instruct"
```

**File**: `config/config_mtup.py` (MTUP)
```python
# Line 42: Change from
MODEL_NAME = MODELS['qwen2.5-3b']

# To:
MODEL_NAME = MODELS['qwen2.5-7b']
```

### Fix 2: Remove Post-processing

**File**: `evaluate_mtup_model.py`
```python
# Line 162-163: Remove these lines
# POST-PROCESSING: Apply conservative repair pipeline (minimal changes)
final_amr = post_process_amr_conservative(final_amr)

# Keep only:
return final_amr
```

**Also remove**:
- `post_process_amr()` function (line 29-107)
- `post_process_amr_conservative()` function (line 62-107)

### Fix 3: Clean Template Format

**File**: `config/prompt_templates.py`

Replace `MTUP_TEMPLATE_V2_NATURAL` with cleaner version:

```python
MTUP_TEMPLATE_V2_NATURAL = """### NHIá»†M Vá»¤
Chuyá»ƒn Ä‘á»•i cÃ¢u tiáº¿ng Viá»‡t sang AMR (2 bÆ°á»›c)

### CÃ‚U Äáº¦U VÃ€O
{sentence}

### Káº¾T QUáº¢

## BÆ¯á»šC 1: Cáº¥u trÃºc AMR (chÆ°a cÃ³ biáº¿n)
{amr_no_vars}

## BÆ¯á»šC 2: GÃ¡n biáº¿n

Quy táº¯c:
- Má»—i khÃ¡i niá»‡m â†’ má»™t biáº¿n (vÃ­ dá»¥: n, p, c)
- KhÃ¡i niá»‡m láº·p láº¡i â†’ dÃ¹ng chung biáº¿n (Ä‘á»“ng tham chiáº¿u)
- Format: (biáº¿n / khÃ¡i_niá»‡m :quan_há»‡ ...)

AMR hoÃ n chá»‰nh:
{amr_with_vars}"""
```

**Changes**:
- âœ… Consistent markdown levels (`###` for main, `##` for steps)
- âœ… No space after colon in headers ("### NHIá»†M Vá»¤" not "### NHIá»†M Vá»¤:")
- âœ… Separated "Quy táº¯c:" section with newline
- âœ… Clearer boundaries
- âœ… Less free text, more structured
- âœ… "AMR hoÃ n chá»‰nh:" on separate line from content

### Fix 4: Clean Input Data

**File**: `src/data_loader.py` (if exists) or preprocessing script

Add trimming for trailing `...`:
```python
def clean_sentence(sentence: str) -> str:
    """Clean input sentence"""
    # Remove trailing ...
    sentence = re.sub(r'\.\.\.+\s*$', '', sentence)
    # Trim whitespace
    sentence = sentence.strip()
    return sentence
```

## ğŸ“ Updated Pipeline Structure

```
Input Sentence
      â†“
[PREPROCESSING]
  - Clean sentence (remove ..., trim)
  - Parse AMR from dataset
  - Remove variables â†’ Task 1 target
  - Keep variables â†’ Task 2 target
      â†“
[TRAINING]
  Model: Qwen 2.5 7B
  Template: v2_natural (cleaned version)

  Baseline:
    Prompt: Simple "Convert to AMR"
    Output: AMR with variables

  MTUP:
    Prompt: Structured 2-step
    Output: Step 1 + Step 2 AMRs
      â†“
[INFERENCE]
  - Generate AMR from trained model
  - NO post-processing âœ…
  - Extract final AMR from Step 2
      â†“
[EVALUATION]
  - SMATCH scoring
  - Compare Baseline vs MTUP
```

## ğŸ“ Why These Changes?

### 1. Same Model = Fair Comparison
- Baseline 14B vs MTUP 3B â†’ Not fair (size difference dominates)
- Both 7B â†’ Isolates the effect of **MTUP methodology**

### 2. No Post-processing = True End-to-End
- **Philosophy**: MTUP teaches LLM to generate correct AMR directly
- Post-processing = admission that LLM failed
- If errors occur â†’ improve training, not add band-aids
- **Result**: Cleaner evaluation of what LLM actually learned

### 3. Clean Template = Better Learning
- Clearer boundaries â†’ Model knows where to output
- Consistent format â†’ Easier to learn
- Less free text â†’ Less confusion
- Structured sections â†’ Better separation of tasks

### 4. Clean Input = Less Noise
- Trailing `...` confuses model
- Clean data â†’ Clean learning

## ğŸ“Š Expected Impact

### Before Fixes
| Metric | Baseline | MTUP | Issue |
|--------|----------|------|-------|
| Model | 14B | 3B | Unfair comparison |
| F1 | ??? | 0.48 | Can't compare |
| Parse errors | ??? | 30% | Post-processing hides real errors |

### After Fixes
| Metric | Baseline | MTUP | Comparison |
|--------|----------|------|------------|
| Model | 7B | 7B | âœ… Fair |
| F1 (expected) | ~0.42-0.45 | ~0.48-0.52 | +13-23% improvement from MTUP |
| Parse errors | ~15-20% | ~10-15% | MTUP should have fewer errors |

**Hypothesis**: MTUP with 7B should **outperform** Baseline with 7B because:
- Task decomposition is easier to learn
- Explicit structure guidance
- Two-stage supervision

## ğŸš€ Next Steps

1. âœ… **Unify models** â†’ Both use Qwen 2.5 7B
2. âœ… **Remove post-processing** â†’ End-to-end LLM only
3. âœ… **Fix template** â†’ Cleaner format
4. âœ… **Update code** â†’ Apply all changes
5. âœ… **Train Baseline** â†’ Get baseline F1 score
6. âœ… **Re-train MTUP** â†’ With same model, clean template
7. âœ… **Compare** â†’ Evaluate improvement

## ğŸ“ Files to Modify

1. `config/config.py` - Change model to 7B
2. `config/config_mtup.py` - Change model to 7B
3. `config/prompt_templates.py` - Fix v2_natural template
4. `evaluate_mtup_model.py` - Remove post-processing
5. `src/preprocessor_mtup.py` - Add input cleaning (if needed)

---

**Philosophy**: End-to-end LLM learning with clean, structured prompts â†’ Better generalization than post-processing hacks
