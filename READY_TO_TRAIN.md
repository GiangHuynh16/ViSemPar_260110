# Baseline 7B - Ready to Train! ðŸš€

**Date**: 2025-12-30
**Status**: âœ… All changes completed, ready to pull and train

---

## âœ… HoÃ n thÃ nh

### 1. Vietnamese Prompt Template

**File**: `config/config.py` lines 117-130

```python
PROMPT_TEMPLATE = """Báº¡n lÃ  chuyÃªn gia phÃ¢n tÃ­ch ngá»¯ nghÄ©a tiáº¿ng Viá»‡t. HÃ£y chuyá»ƒn Ä‘á»•i cÃ¢u sau sang Ä‘á»‹nh dáº¡ng AMR (Abstract Meaning Representation).

Quy táº¯c quan trá»ng:
- Sá»­ dá»¥ng khÃ¡i niá»‡m tiáº¿ng Viá»‡t cÃ³ dáº¥u gáº¡ch dÆ°á»›i (vÃ­ dá»¥: chá»§_tá»‹ch, mÃ´i_trÆ°á»ng)
- GÃ¡n biáº¿n cho má»—i khÃ¡i niá»‡m (vÃ­ dá»¥: c / chá»§_tá»‹ch)
- Sá»­ dá»¥ng quan há»‡ chuáº©n AMR (:ARG0, :ARG1, :time, :location, etc.)
- Giá»¯ nguyÃªn cáº¥u trÃºc cÃ¢y vá»›i dáº¥u ngoáº·c Ä‘Æ¡n cÃ¢n báº±ng
- Äáº£m báº£o táº¥t cáº£ biáº¿n Ä‘Æ°á»£c Ä‘á»‹nh nghÄ©a trÆ°á»›c khi sá»­ dá»¥ng

CÃ¢u tiáº¿ng Viá»‡t: {sentence}

AMR:
"""
```

**Æ¯u Ä‘iá»ƒm**:
- âœ… Vietnamese (match vá»›i MTUP)
- âœ… Explicit rules (5 quy táº¯c rÃµ rÃ ng)
- âœ… Concrete examples (chá»§_tá»‹ch, c / chá»§_tá»‹ch)
- âœ… Error prevention (parentheses, variables)

### 2. Minimal Postprocessing

**File**: `evaluate_baseline_model.py` lines 22-40

```python
def post_process_amr_conservative(amr_string: str) -> str:
    """
    Minimal post-processing - extract AMR only, NO heavy processing
    Philosophy: Let LLM output speak for itself, trust the model
    """
    if not amr_string or len(amr_string) < 3:
        return "(amr-empty)"

    amr = amr_string.strip()

    # Simply find first '(' and take everything from there
    if '(' in amr:
        amr = amr[amr.index('('):]

    # Basic whitespace normalization only
    amr = re.sub(r'\s+', ' ', amr).strip()

    return amr
```

**Philosophy**:
- âœ… NO parentheses balancing (trust LLM)
- âœ… NO marker removal (simple extraction)
- âœ… NO structural fixes (LLM should get it right)
- âœ… ONLY basic whitespace cleaning

### 3. Minimal Preprocessing

**File**: `config/config.py` lines 101-111

```python
PREPROCESSING_CONFIG = {
    "preserve_coreference": True,       # Keep coreference
    "normalize_concepts": False,        # Let LLM learn
    "handle_multiword": False,          # Let LLM learn underscores
    "fix_malformed_amr": True,          # Only fix broken data
    "remove_variables": False,          # Keep variables
    "clean_whitespace": True,           # Basic cleaning
    "validate_structure": True,         # Validate parentheses
}
```

---

## ðŸ“Š Template So SÃ¡nh

### Baseline Template (Vietnamese)

```
Báº¡n lÃ  chuyÃªn gia phÃ¢n tÃ­ch ngá»¯ nghÄ©a tiáº¿ng Viá»‡t. HÃ£y chuyá»ƒn Ä‘á»•i cÃ¢u sau sang Ä‘á»‹nh dáº¡ng AMR (Abstract Meaning Representation).

Quy táº¯c quan trá»ng:
- Sá»­ dá»¥ng khÃ¡i niá»‡m tiáº¿ng Viá»‡t cÃ³ dáº¥u gáº¡ch dÆ°á»›i (vÃ­ dá»¥: chá»§_tá»‹ch, mÃ´i_trÆ°á»ng)
- GÃ¡n biáº¿n cho má»—i khÃ¡i niá»‡m (vÃ­ dá»¥: c / chá»§_tá»‹ch)
- Sá»­ dá»¥ng quan há»‡ chuáº©n AMR (:ARG0, :ARG1, :time, :location, etc.)
- Giá»¯ nguyÃªn cáº¥u trÃºc cÃ¢y vá»›i dáº¥u ngoáº·c Ä‘Æ¡n cÃ¢n báº±ng
- Äáº£m báº£o táº¥t cáº£ biáº¿n Ä‘Æ°á»£c Ä‘á»‹nh nghÄ©a trÆ°á»›c khi sá»­ dá»¥ng

CÃ¢u tiáº¿ng Viá»‡t: {sentence}

AMR:
```

### MTUP Template (Vietnamese, 2-stage)

```
### NHIá»†M Vá»¤: Chuyá»ƒn Ä‘á»•i cÃ¢u tiáº¿ng Viá»‡t sang AMR (2 bÆ°á»›c)

### CÃ¢u cáº§n phÃ¢n tÃ­ch:
{sentence}

### Káº¿t quáº£ phÃ¢n tÃ­ch:

## BÆ°á»›c 1 - Táº¡o cáº¥u trÃºc AMR (chÆ°a cÃ³ biáº¿n):
[...]

## BÆ°á»›c 2 - GÃ¡n biáº¿n vÃ  hoÃ n thiá»‡n:
AMR hoÃ n chá»‰nh:
[...]
```

### So sÃ¡nh

| Aspect | Baseline | MTUP |
|--------|----------|------|
| **Language** | Vietnamese âœ… | Vietnamese âœ… |
| **Stages** | 1 (direct) | 2 (decomposed) |
| **Rules** | 5 explicit rules | 2-stage guidance |
| **Examples** | Inline (chá»§_tá»‹ch, c / chá»§_tá»‹ch) | Structured |
| **Postprocessing** | Minimal (find '(') | Conservative |

**Fair comparison**: Cáº£ hai Ä‘á»u Vietnamese, chá»‰ khÃ¡c á»Ÿ task decomposition!

---

## ðŸ”§ HÆ°á»›ng dáº«n Pull vÃ  Train

### BÆ°á»›c 1: SSH vÃ o server

```bash
ssh your-server
cd ViSemPar_new1
```

### BÆ°á»›c 2: Pull code má»›i

```bash
# Stash local changes (if any)
git stash

# Pull latest
git pull origin main

# Apply stashed changes (if needed)
git stash pop
```

### BÆ°á»›c 3: Verify changes

```bash
# Check prompt template
head -n 20 config/config.py | grep -A 15 "PROMPT_TEMPLATE"
```

**Expected output** (Vietnamese template):
```
PROMPT_TEMPLATE = """Báº¡n lÃ  chuyÃªn gia phÃ¢n tÃ­ch ngá»¯ nghÄ©a tiáº¿ng Viá»‡t...
```

âœ… **Náº¿u tháº¥y "Báº¡n lÃ  chuyÃªn gia"** â†’ Pull thÃ nh cÃ´ng!
âŒ **Náº¿u tháº¥y "Below is an instruction"** â†’ Pull láº¡i hoáº·c check branch

### BÆ°á»›c 4: Verify postprocessing

```bash
grep -A 10 "def post_process_amr" evaluate_baseline_model.py
```

**Expected**: Should see "Minimal post-processing" comment and simple logic (no balancing)

### BÆ°á»›c 5: Start training

```bash
# Create tmux session
tmux new -s baseline_7b

# Run training
bash START_BASELINE_7B_TRAINING.sh

# Detach: Ctrl+B, then D
```

### BÆ°á»›c 6: Monitor

```bash
# Reattach
tmux attach -t baseline_7b

# Check logs
tail -f logs/training.log

# GPU
watch -n 1 nvidia-smi
```

---

## ðŸ“ Quick Command Summary

```bash
# Pull code
cd ViSemPar_new1 && git pull origin main

# Verify template
grep "Báº¡n lÃ  chuyÃªn gia" config/config.py

# Start training
tmux new -s baseline_7b
bash START_BASELINE_7B_TRAINING.sh
# Ctrl+B, D to detach

# Monitor
tmux attach -t baseline_7b
tail -f logs/training.log
```

---

## ðŸŽ¯ Expected Results

### Training
- **Model**: Qwen 2.5 7B
- **LoRA rank**: 128
- **Epochs**: 15
- **Time**: ~12-15 hours
- **Trainable params**: ~239M (same as MTUP)

### Performance Hypothesis

| Model | Template | Expected F1 | Notes |
|-------|----------|-------------|-------|
| MTUP 7B | Vietnamese + 2-stage | 0.51-0.52 | âœ… Completed |
| Baseline 7B | Vietnamese + 1-stage | 0.47-0.50 | â³ To train |

**Gap**: 0.02-0.04 F1 (MTUP advantage from task decomposition)

**Why smaller gap?**
- Both use Vietnamese (language consistency)
- Both have explicit rules (AMR guidance)
- Only difference: Task decomposition (1-stage vs 2-stage)

---

## âœ… Checklist Before Training

- [ ] Code pulled (`git pull origin main`)
- [ ] Prompt is Vietnamese (`grep "Báº¡n lÃ  chuyÃªn gia" config/config.py`)
- [ ] Postprocessing is minimal (check `evaluate_baseline_model.py`)
- [ ] Data files exist (`ls data/train_amr_*.txt`)
- [ ] VRAM >= 18GB (`nvidia-smi`)
- [ ] In tmux session (`echo $TMUX` not empty)

---

## ðŸš€ Ready!

**Táº¥t cáº£ Ä‘Ã£ sáºµn sÃ ng!** Chá»‰ cáº§n:

1. SSH vÃ o server
2. `git pull origin main`
3. Verify template lÃ  Vietnamese
4. `bash START_BASELINE_7B_TRAINING.sh`

**Good luck!** ðŸŽ¯
