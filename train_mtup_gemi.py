import os
import argparse
import torch
from datasets import Dataset
from transformers import (
    AutoModelForCausalLM,
    AutoTokenizer,
    BitsAndBytesConfig,
    TrainingArguments,
)
from peft import LoraConfig
from trl import SFTTrainer

# ==========================================
# 1. TEMPLATE & PROMPTS (Cá»°C Ká»² QUAN TRá»ŒNG)
# ==========================================

def create_prompt_stage1(sentence, target_amr=None):
    """
    Stage 1: Text -> AMR No Vars (Structure)
    Nháº¥n máº¡nh: PENMAN format, parentheses balance, no variables.
    """
    sys_prompt = """Báº¡n lÃ  má»™t chuyÃªn gia ngÃ´n ngá»¯ há»c vá» cáº¥u trÃºc AMR (Abstract Meaning Representation).
Nhiá»‡m vá»¥: Chuyá»ƒn Ä‘á»•i cÃ¢u tiáº¿ng Viá»‡t Ä‘áº§u vÃ o sang Ä‘á»‹nh dáº¡ng Ä‘á»“ thá»‹ AMR chuáº©n PENMAN.
YÃªu cáº§u Ä‘áº·c biá»‡t:
1. KHÃ”NG sá»­ dá»¥ng biáº¿n (variables) Ä‘á»‹nh danh (vÃ­ dá»¥: khÃ´ng dÃ¹ng 't / tÃ´i', chá»‰ dÃ¹ng '(tÃ´i)').
2. Äáº£m báº£o cáº¥u trÃºc ngoáº·c Ä‘Æ¡n () cÃ¢n báº±ng chÃ­nh xÃ¡c.
3. Chá»‰ giá»¯ láº¡i cÃ¡c Concept vÃ  Relation (vÃ­ dá»¥: :ARG0, :ARG1, :mod).

VÃ­ dá»¥ máº«u:
Input: Cáº­u bÃ© Ä‘ang Ä‘á»c sÃ¡ch.
Output: (Ä‘á»c :ARG0 (cáº­u_bÃ©) :ARG1 (sÃ¡ch))"""

    user_input = f"Input: {sentence}"
    
    # Format theo ChatML cá»§a Qwen
    prompt = f"<|im_start|>system\n{sys_prompt}<|im_end|>\n<|im_start|>user\n{user_input}<|im_end|>\n<|im_start|>assistant\n"
    
    if target_amr:
        prompt += f"{target_amr}<|im_end|>"
    return prompt

def create_prompt_stage2(sentence, amr_no_vars, target_full_amr=None):
    """
    Stage 2: Text + AMR No Vars -> Full AMR (Alignment & Re-entrancy)
    Cáº¬P NHáº¬T: Sá»­ dá»¥ng vÃ­ dá»¥ 'Hard' cÃ³ Re-entrancy (Nam - cáº­u áº¥y).
    """
    sys_prompt = """Báº¡n lÃ  má»™t chuyÃªn gia gÃ¡n nhÃ£n dá»¯ liá»‡u AMR (Abstract Meaning Representation).
Nhiá»‡m vá»¥: HoÃ n thiá»‡n Ä‘á»“ thá»‹ AMR chuáº©n PENMAN tá»« cáº¥u trÃºc thÃ´ (chÆ°a cÃ³ biáº¿n) vÃ  cÃ¢u gá»‘c.

YÃªu cáº§u QUAN TRá»ŒNG:
1. GÃ¡n biáº¿n (variables) Ä‘á»‹nh danh cho má»—i concept (vd: '(tÃ´i)' -> '(t / tÃ´i)').
2. TÃI Sá»¬ Dá»¤NG BIáº¾N (Re-entrancy): Náº¿u má»™t Ä‘á»‘i tÆ°á»£ng xuáº¥t hiá»‡n nhiá»u láº§n hoáº·c Ä‘Æ°á»£c thay tháº¿ báº±ng Ä‘áº¡i tá»« (anh áº¥y, nÃ³, cáº­u ta...), hÃ£y dÃ¹ng láº¡i biáº¿n Ä‘Ã£ khai bÃ¡o trÆ°á»›c Ä‘Ã³ thay vÃ¬ táº¡o biáº¿n má»›i.
3. Äáº£m báº£o Ä‘Ãºng Ä‘á»‹nh dáº¡ng PENMAN.

VÃ­ dá»¥ máº«u (Complex Re-entrancy):
Input: Nam cá»‘ gáº¯ng há»c bÃ i vÃ¬ cáº­u áº¥y muá»‘n Ä‘á»—. <sep> (cá»‘_gáº¯ng :ARG0 (Nam) :ARG1 (há»c :ARG1 (bÃ i)) :cause (muá»‘n :ARG0 (cáº­u_áº¥y) :ARG1 (Ä‘á»—)))
Output: (c / cá»‘_gáº¯ng
    :ARG0 (n / Nam)             <-- Khai bÃ¡o biáº¿n 'n' cho Nam
    :ARG1 (h / há»c
        :ARG0 n                 <-- DÃ¹ng láº¡i 'n' (Nam lÃ  ngÆ°á»i há»c)
        :ARG1 (b / bÃ i))
    :cause (m / muá»‘n
        :ARG0 n                 <-- DÃ¹ng láº¡i 'n' (cáº­u áº¥y chÃ­nh lÃ  Nam)
        :ARG1 (Ä‘ / Ä‘á»—
            :ARG0 n)))          <-- DÃ¹ng láº¡i 'n' (Nam lÃ  ngÆ°á»i Ä‘á»—)"""

    # GhÃ©p input thá»±c táº¿
    user_input = f"Input: {sentence} <sep> {amr_no_vars}"
    
    # Format ChatML
    prompt = f"<|im_start|>system\n{sys_prompt}<|im_end|>\n<|im_start|>user\n{user_input}<|im_end|>\n<|im_start|>assistant\n"
    
    if target_full_amr:
        prompt += f"{target_full_amr}<|im_end|>"
    return prompt

def format_data(sample, stage):
    text = sample['text']
    try:
        if stage == 1:
            # Parse format tá»« file train_stage1.txt
            sent = text.split("SENT: ")[1].split("\nAMR: ")[0].strip()
            amr = text.split("\nAMR: ")[1].strip()
            return create_prompt_stage1(sent, amr)
        else:
            # Parse format tá»« file train_stage2.txt
            sent = text.split("SENT: ")[1].split("\nNO_VAR: ")[0].strip()
            no_var = text.split("\nNO_VAR: ")[1].split("\nFULL: ")[0].strip()
            full = text.split("\nFULL: ")[1].strip()
            return create_prompt_stage2(sent, no_var, full)
    except:
        return ""

# ==========================================
# 2. TRAINING SETUP
# ==========================================

def load_dataset_from_text(file_path):
    with open(file_path, 'r', encoding='utf-8') as f:
        content = f.read()
    blocks = content.strip().split('\n\n')
    return Dataset.from_dict({"text": blocks})

def train(args):
    print(f"ğŸš€ START TRAINING STAGE {args.stage} | GPU 48GB Optimization")
    
    dataset = load_dataset_from_text(args.data_path)
    
    # 1. LOAD MODEL (Sá»­a: Chá»‰ giá»¯ láº¡i 1 láº§n khai bÃ¡o chuáº©n BFloat16)
    print("âœ¨ GPU 48GB Detected: Loading model in BFloat16 (No Quantization needed)")
    
    model = AutoModelForCausalLM.from_pretrained(
        args.model_name,
        torch_dtype=torch.bfloat16,       # Cháº¡y Native 16-bit (KhÃ´ng cáº§n bitsandbytes)
        device_map="auto",
        attn_implementation="flash_attention_2" 
    )
    
    # (ÄÃƒ XÃ“A Ä‘oáº¡n khai bÃ¡o model láº§n 2 bá»‹ thá»«a á»Ÿ Ä‘Ã¢y)
    
    tokenizer = AutoTokenizer.from_pretrained(args.model_name)
    tokenizer.pad_token = tokenizer.eos_token
    
    # 2. LORA CONFIG
    peft_config = LoraConfig(
        lora_alpha=64,
        lora_dropout=0.05,
        r=128,
        bias="none",
        task_type="CAUSAL_LM",
        target_modules=["q_proj", "k_proj", "v_proj", "o_proj", "gate_proj", "up_proj", "down_proj"]
    )

    # 3. TRAINING ARGS
    training_args = TrainingArguments(
        output_dir=args.output_dir,
        num_train_epochs=args.epochs,
        per_device_train_batch_size=8,      
        gradient_accumulation_steps=4,      
        learning_rate=2e-4,
        weight_decay=0.01,
        
        # Sá»¬A QUAN TRá»ŒNG: Äá»•i fp16 thÃ nh bf16 Ä‘á»ƒ khá»›p vá»›i model torch_dtype=torch.bfloat16
        bf16=True,       # Tá»‘t hÆ¡n fp16 trÃªn A100/A6000/3090/4090
        fp16=False,      # Táº¯t fp16 Ä‘i
        
        logging_steps=10,
        save_strategy="epoch",
        optim="paged_adamw_32bit",
        report_to="none"
    )

    trainer = SFTTrainer(
        model=model,
        train_dataset=dataset,
        peft_config=peft_config,
        formatting_func=lambda x: [format_data(item, args.stage) for item in x],
        tokenizer=tokenizer,
        args=training_args,
        max_seq_length=2048,
    )

    trainer.train()
    
    # Save Final
    final_path = os.path.join(args.output_dir, "final_adapter")
    trainer.model.save_pretrained(final_path)
    tokenizer.save_pretrained(final_path)
    print(f"âœ… Training Done. Saved to {final_path}")

if __name__ == "__main__":
    parser = argparse.ArgumentParser()
    parser.add_argument("--stage", type=int, required=True)
    parser.add_argument("--data_path", type=str, required=True)
    parser.add_argument("--model_name", type=str, default="Qwen/Qwen2.5-7B-Instruct") 
    parser.add_argument("--output_dir", type=str, required=True)
    parser.add_argument("--epochs", type=int, default=5) # Train 5 epochs cho cháº¯c
    
    args = parser.parse_args()
    train(args)