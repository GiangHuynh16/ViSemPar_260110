# MTUP v2 - Quick Start Guide

## Tá»•ng quan

MTUP v2 (Multi-Task Unified Prompting) lÃ  phÆ°Æ¡ng phÃ¡p train **1 MODEL duy nháº¥t** vá»›i **1 PROMPT chung** cho **2 TASKS**:
- **Task 1**: Sentence â†’ AMR Skeleton (khÃ´ng cÃ³ biáº¿n)
- **Task 2**: Sentence â†’ Full AMR (cÃ³ biáº¿n, chuáº©n PENMAN)

**Má»¥c tiÃªu**: Äáº¡t F1 > 0.47 (baseline)

## KhÃ¡c biá»‡t so vá»›i v1

| Aspect | v1 (SAI) | v2 (ÄÃšNG) |
|--------|----------|-----------|
| Sá»‘ models | 2 models riÃªng | 1 model chung |
| Prompt | 2 prompts riÃªng | 1 prompt unified |
| Training | Train 2 láº§n | Train 1 láº§n |
| Method | Two-stage pipeline | Multi-task learning |

## Workflow nhanh

### 1. Preprocessing (Local)
```bash
python mtup_v2/preprocessing/create_mtup_data.py
```
â†’ Táº¡o `data/train_mtup_unified.txt`

### 2. Training (Server)
```bash
# Copy project lÃªn server
scp -r mtup_v2/ user@server:/path/to/ViSemPar_new1/

# SSH vÃ o server
ssh user@server

# Train
cd /path/to/ViSemPar_new1
python mtup_v2/scripts/train_mtup_unified.py \
    --data_path data/train_mtup_unified.txt \
    --model_name Qwen/Qwen2.5-7B-Instruct \
    --output_dir outputs/mtup_v2 \
    --epochs 5
```

### 3. Prediction (Server)
```bash
python mtup_v2/scripts/predict_mtup_unified.py \
    --base_model Qwen/Qwen2.5-7B-Instruct \
    --adapter_path outputs/mtup_v2/final_adapter \
    --input_file data/public_test.txt \
    --output_file outputs/predictions.txt
```

### 4. Evaluation (Local hoáº·c Server)
```bash
python mtup_v2/scripts/evaluate.py \
    --predictions outputs/predictions.txt \
    --ground_truth data/public_test_ground_truth.txt
```

## Cáº¥u trÃºc files

```
ViSemPar_new1/
â”œâ”€â”€ mtup_v2/                          # â† NEW VERSION
â”‚   â”œâ”€â”€ scripts/
â”‚   â”‚   â”œâ”€â”€ train_mtup_unified.py     # Training script
â”‚   â”‚   â”œâ”€â”€ predict_mtup_unified.py   # Prediction script
â”‚   â”‚   â””â”€â”€ evaluate.py               # Evaluation script
â”‚   â”œâ”€â”€ preprocessing/
â”‚   â”‚   â””â”€â”€ create_mtup_data.py       # Data preprocessing
â”‚   â””â”€â”€ docs/
â”‚       â”œâ”€â”€ README.md                 # Overview
â”‚       â”œâ”€â”€ MTUP_CONCEPT.md           # Concept explanation
â”‚       â”œâ”€â”€ TRAINING_GUIDE.md         # Detailed guide
â”‚       â””â”€â”€ COREFERENCE_EXAMPLES.md   # Co-reference examples
â”‚
â”œâ”€â”€ archive/
â”‚   â””â”€â”€ mtup_v1/                      # â† OLD VERSION (archived)
â”‚       â”œâ”€â”€ train_mtup*.py            # Old training scripts
â”‚       â””â”€â”€ *.md                      # Old documentation
â”‚
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ train_amr_mtup_preprocessed.txt  # Input data
â”‚   â”œâ”€â”€ train_mtup_unified.txt           # Generated by preprocessing
â”‚   â”œâ”€â”€ public_test.txt                  # Test input
â”‚   â””â”€â”€ public_test_ground_truth.txt     # Ground truth
â”‚
â””â”€â”€ outputs/
    â””â”€â”€ mtup_v2/                         # Training output
        â””â”€â”€ final_adapter/               # Trained model
```

## CÃ¡c Ä‘iá»ƒm quan trá»ng

### âœ… DO: NÃªn lÃ m

1. **Validate data trÆ°á»›c khi train:**
   ```bash
   # Check sá»‘ samples valid
   python mtup_v2/preprocessing/create_mtup_data.py
   # Should show: "âœ… Parsed X samples"
   ```

2. **Monitor training:**
   ```bash
   # Check loss giáº£m dáº§n
   tail -f logs/train_mtup_v2.log

   # Check GPU
   nvidia-smi -l 1
   ```

3. **Test predictions format:**
   ```bash
   # Should have '/' (variables)
   head -1 outputs/predictions.txt | grep "/"
   ```

4. **Backup checkpoints:**
   ```bash
   cp -r outputs/mtup_v2/checkpoint-epoch-3 outputs/backup/
   ```

### âŒ DON'T: TrÃ¡nh lÃ m

1. âŒ Train 2 models riÃªng (Ä‘Ã³ lÃ  pipeline, khÃ´ng pháº£i MTUP)
2. âŒ Bá» qua data validation
3. âŒ QuÃªn check co-reference trong output
4. âŒ Train vá»›i data cÃ³ lá»—i bracket balance
5. âŒ DÃ¹ng batch size quÃ¡ lá»›n (OOM)

## Co-reference Resolution

**Quan trá»ng nháº¥t:** Model pháº£i há»c tÃ¡i sá»­ dá»¥ng biáº¿n!

### VÃ­ dá»¥:
```
CÃ¢u: TÃ´i lÃ  bÃ¡c sÄ©. TÃ´i lÃ m á»Ÿ bá»‡nh viá»‡n.

âœ… ÄÃšNG:
(a / and
    :op1(b / bÃ¡c_sÄ© :domain(t / tÃ´i))
    :op2(l / lÃ m :ARG0 t :location(b2 / bá»‡nh_viá»‡n)))
                    â†‘
                    TÃ¡i sá»­ dá»¥ng biáº¿n 't'

âŒ SAI:
(a / and
    :op1(b / bÃ¡c_sÄ© :domain(t / tÃ´i))
    :op2(l / lÃ m :ARG0(t / tÃ´i) :location(b2 / bá»‡nh_viá»‡n)))
                    â†‘
                    Äá»‹nh nghÄ©a láº¡i 't' â†’ Duplicate error!
```

Xem thÃªm: [mtup_v2/docs/COREFERENCE_EXAMPLES.md](mtup_v2/docs/COREFERENCE_EXAMPLES.md)

## Expected Results

### Training
- Time: ~2-3 hours (5 epochs, RTX 4090)
- Loss: Start ~2.5 â†’ End ~1.0
- VRAM: ~20-22GB

### Evaluation
```
Target: F1 > 0.47 (baseline)

Best case: F1 ~0.50-0.55 (improvement +6% to +17%)
Acceptable: F1 ~0.48-0.50 (improvement +2% to +6%)
Need work: F1 < 0.47 (below baseline)
```

## Troubleshooting

### OOM Error
```bash
# Giáº£m batch size trong train_mtup_unified.py:
per_device_train_batch_size=1
gradient_accumulation_steps=32
```

### No variables in predictions
```bash
# Model chÆ°a há»c Task 2 tá»‘t
# Solution: Train lÃ¢u hÆ¡n
--epochs 10
```

### Duplicate node errors
```bash
# Model chÆ°a há»c co-reference
# Solution: Check training data cÃ³ Ä‘á»§ co-reference examples
grep -A 5 "multi-sentence" data/train_mtup_unified.txt
```

## Next Steps

1. âœ… Äá»c concept: [mtup_v2/docs/MTUP_CONCEPT.md](mtup_v2/docs/MTUP_CONCEPT.md)
2. âœ… Cháº¡y preprocessing: `python mtup_v2/preprocessing/create_mtup_data.py`
3. âœ… Äá»c training guide: [mtup_v2/docs/TRAINING_GUIDE.md](mtup_v2/docs/TRAINING_GUIDE.md)
4. âœ… Train trÃªn server
5. âœ… Evaluate vÃ  so sÃ¡nh vá»›i baseline

## Commands Tá»•ng há»£p

```bash
# === PREPROCESSING ===
python mtup_v2/preprocessing/create_mtup_data.py

# === TRAINING (SERVER) ===
python mtup_v2/scripts/train_mtup_unified.py \
    --data_path data/train_mtup_unified.txt \
    --model_name Qwen/Qwen2.5-7B-Instruct \
    --output_dir outputs/mtup_v2 \
    --epochs 5

# === PREDICTION (SERVER) ===
python mtup_v2/scripts/predict_mtup_unified.py \
    --base_model Qwen/Qwen2.5-7B-Instruct \
    --adapter_path outputs/mtup_v2/final_adapter \
    --input_file data/public_test.txt \
    --output_file outputs/predictions.txt

# === EVALUATION ===
python mtup_v2/scripts/evaluate.py \
    --predictions outputs/predictions.txt \
    --ground_truth data/public_test_ground_truth.txt
```

## Support

- Documentation: `mtup_v2/docs/`
- Old version: `archive/mtup_v1/` (for reference only)
- Questions: Check training guide hoáº·c co-reference examples

---

**Good luck vá»›i MTUP v2! ðŸš€**

Target: F1 > 0.47 â†’ Let's beat the baseline! ðŸ’ª
