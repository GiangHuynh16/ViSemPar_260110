# üöÄ How to Run Full Evaluation

## Quick Start (Recommended)

### Tr√™n Server:

```bash
cd ~/ViSemPar_new1
git pull origin main

# Ch·∫°y full evaluation trong tmux (tr√°nh disconnect)
bash RUN_FULL_EVALUATION_TMUX.sh
```

Xong! Script s·∫Ω t·ª± ƒë·ªông:
- T√¨m checkpoint m·ªõi nh·∫•t
- Ch·∫°y evaluation tr√™n T·∫§T C·∫¢ test samples
- L∆∞u k·∫øt qu·∫£ v√†o `outputs/evaluation_results_full_TIMESTAMP.json`

---

## Monitor Progress

### Xem live progress:
```bash
tmux attach -t mtup_eval
# Press Ctrl+B then D to detach
```

### Check status nhanh:
```bash
bash CHECK_EVALUATION_STATUS.sh
```

### Xem log real-time:
```bash
tail -f outputs/evaluation_full_*.log
```

---

## Expected Timeline

D·ª±a tr√™n test v·ªõi 10 samples (~200 seconds):
- **10 samples**: ~3 minutes
- **50 samples**: ~17 minutes
- **200 samples**: ~67 minutes (~1 hour)
- **500 samples**: ~2.8 hours

C√¥ng th·ª©c: `samples * 20 seconds / 60 = minutes`

---

## Results

### Khi ho√†n th√†nh, b·∫°n s·∫Ω th·∫•y:

```
================================================================================
EVALUATION RESULTS
================================================================================

Processed: XXX/XXX examples
Errors:    YYY

================================================================================
SMATCH SCORES
================================================================================
  Precision: 0.XXXX
  Recall:    0.XXXX
  F1:        0.XXXX
================================================================================
```

### View k·∫øt qu·∫£:

```bash
# Find latest results file
ls -t outputs/evaluation_results_full_*.json | head -1

# View formatted
cat outputs/evaluation_results_full_TIMESTAMP.json | python3 -m json.tool
```

---

## Manual Run (Without tmux)

N·∫øu kh√¥ng mu·ªën d√πng tmux:

```bash
bash RUN_FULL_EVALUATION.sh
```

**‚ö†Ô∏è L∆∞u √Ω**: N·∫øu SSH b·ªã disconnect, qu√° tr√¨nh s·∫Ω d·ª´ng!

---

## Troubleshooting

### Evaluation b·ªã stuck?

```bash
# Check n·∫øu process c√≤n ch·∫°y
ps aux | grep evaluate_mtup_model.py

# Check GPU usage
nvidia-smi

# Check log
tail -30 outputs/evaluation_full_*.log
```

### Stop evaluation:

```bash
# Kill tmux session
tmux kill-session -t mtup_eval

# OR kill process directly
pkill -f evaluate_mtup_model.py
```

### Restart evaluation:

```bash
# Kill existing session first
tmux kill-session -t mtup_eval

# Then restart
bash RUN_FULL_EVALUATION_TMUX.sh
```

---

## File Outputs

Sau khi ch·∫°y, b·∫°n s·∫Ω c√≥:

```
outputs/
‚îú‚îÄ‚îÄ evaluation_results_full_TIMESTAMP.json  ‚Üê Results (precision, recall, F1)
‚îú‚îÄ‚îÄ evaluation_full_TIMESTAMP.log           ‚Üê Full log
```

Timestamp format: `YYYYMMDD_HHMMSS` (v√≠ d·ª•: `20231225_143052`)

---

## Current Status

Quick test (10 samples) results:
- ‚úÖ Processed: 7/10 examples (70%)
- ‚úÖ F1 Score: **0.4933** (~49%)
- ‚úÖ Precision: 0.4978
- ‚úÖ Recall: 0.5002

**Next**: Run full evaluation ƒë·ªÉ c√≥ F1 ch√≠nh x√°c tr√™n to√†n b·ªô test set!

---

## Scripts Available

| Script | Purpose |
|--------|---------|
| `RUN_FULL_EVALUATION.sh` | Run evaluation (foreground) |
| `RUN_FULL_EVALUATION_TMUX.sh` | Run in tmux (recommended) |
| `CHECK_EVALUATION_STATUS.sh` | Check progress |
| `evaluate_mtup_model.py` | Main evaluation code |

---

## After Evaluation

Sau khi c√≥ F1 score tr√™n full test set:

1. **N·∫øu F1 > 0.55**: T·ªët! Model ƒë√£ h·ªçc t·ªët
2. **N·∫øu F1 = 0.45-0.55**: Acceptable, c√≥ th·ªÉ improve
3. **N·∫øu F1 < 0.45**: C·∫ßn train th√™m ho·∫∑c tune hyperparameters

### Next Steps sau evaluation:
- Ph√¢n t√≠ch errors (duplicate nodes, unmatched parens)
- Train v·ªõi epochs/batch size l·ªõn h∆°n
- Th·ª≠ template kh√°c (v5_cot)
- Compare v·ªõi baseline models
