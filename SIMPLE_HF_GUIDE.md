# ðŸš€ HÆ°á»›ng Dáº«n Push Model LÃªn HuggingFace - Cá»°C ÄÆ N GIáº¢N

## ðŸŽ¯ Táº¡i Sao DÃ¹ng HF?

VÃ¬ báº¡n muá»‘n **build API á»Ÿ local**, khÃ´ng pháº£i server:
- âœ… Download vá» local trong 1-2 phÃºt
- âœ… DÃ¹ng Ä‘Æ°á»£c á»Ÿ báº¥t ká»³ Ä‘Ã¢u
- âœ… KhÃ´ng cáº§n SSH vÃ o server má»—i láº§n
- âœ… Professional nhÆ° cÃ¡c model SOTA

## ðŸ“‹ 3 BÆ°á»›c Cá»±c ÄÆ¡n Giáº£n

### BÆ°á»›c 1: Láº¥y HuggingFace Token (1 láº§n duy nháº¥t)

1. VÃ o https://huggingface.co/settings/tokens
2. Click **"New token"**
3. Äáº·t tÃªn: `model-upload`
4. Chá»n **"Write"** permission
5. Click **"Generate"**
6. **Copy token** (dáº¡ng `hf_...`)

### BÆ°á»›c 2: Setup .env File (1 láº§n duy nháº¥t)

```bash
# On server
cd ~/ViSemPar_new1

# Copy example to .env
cp .env.example .env

# Edit .env file
nano .env
# Hoáº·c: vim .env
```

**Trong file .env**, thay tháº¿:
```bash
HF_TOKEN=hf_your_token_here      # â† Paste token tá»« BÆ°á»›c 1
HF_USERNAME=your_username        # â† Thay báº±ng username HF cá»§a báº¡n

# Optional: TÃ¹y chá»‰nh tÃªn repo
HF_REPO_MTUP=vietnamese-amr-mtup-7b
HF_REPO_BASELINE=vietnamese-amr-baseline-7b
MAKE_PRIVATE=true  # true = private, false = public
```

Save file (Ctrl+X, Y, Enter náº¿u dÃ¹ng nano)

### BÆ°á»›c 3: Push Model (Sau khi train xong)

```bash
# Install python-dotenv (náº¿u chÆ°a cÃ³)
pip install python-dotenv

# Push MTUP model
python3 push_to_hf_simple.py --model-type mtup

# Hoáº·c push Baseline model
python3 push_to_hf_simple.py --model-type baseline
```

**Chá»‰ cáº§n váº­y thÃ´i!** ðŸŽ‰

## ðŸ“Š Output Máº«u

```
================================================================================
ðŸš€ PUSHING MTUP MODEL TO HUGGINGFACE HUB
================================================================================

ðŸ“ Local path: outputs/models/mtup_two_task_7b
ðŸ‘¤ Username:   your-username
ðŸ“¦ Repo name:  vietnamese-amr-mtup-7b
ðŸ” Private:    True

ðŸ” Logging in to HuggingFace...
âœ… Logged in successfully!

ðŸ“¦ Creating repository: your-username/vietnamese-amr-mtup-7b...
âœ… Repository ready!

ðŸ“ Creating model card...
âœ… Model card created

ðŸ“¤ Uploading files to HuggingFace Hub...
   This may take 2-3 minutes...

================================================================================
âœ… SUCCESS! MODEL PUSHED TO HUGGINGFACE HUB
================================================================================

ðŸ”— Model URL: https://huggingface.co/your-username/vietnamese-amr-mtup-7b

ðŸ“¥ To use on your local machine:

from peft import PeftModel
from transformers import AutoModelForCausalLM

model = PeftModel.from_pretrained(
    AutoModelForCausalLM.from_pretrained("Qwen/Qwen2.5-7B-Instruct"),
    "your-username/vietnamese-amr-mtup-7b"
)

âœ… You can now delete the model from server to save space!
   rm -rf outputs/models/mtup_two_task_7b
```

## ðŸŒ DÃ¹ng Model TrÃªn Local Machine

### CÃ¡ch 1: Python Script

```python
# On your laptop
from transformers import AutoModelForCausalLM, AutoTokenizer
from peft import PeftModel
import torch

# Load from HuggingFace (auto-download)
base = AutoModelForCausalLM.from_pretrained(
    "Qwen/Qwen2.5-7B-Instruct",
    device_map="auto",
    torch_dtype=torch.float16
)

model = PeftModel.from_pretrained(
    base,
    "your-username/vietnamese-amr-mtup-7b"  # â† Your HF repo
)

tokenizer = AutoTokenizer.from_pretrained(
    "your-username/vietnamese-amr-mtup-7b"
)

# Parse sentence
sentence = "TÃ´i yÃªu Viá»‡t Nam"
prompt = f"""### NHIá»†M Vá»¤
Chuyá»ƒn Ä‘á»•i cÃ¢u tiáº¿ng Viá»‡t sang AMR (2 bÆ°á»›c)

### CÃ‚U Äáº¦U VÃ€O
{sentence}

### Káº¾T QUáº¢

## BÆ¯á»šC 1: Cáº¥u trÃºc AMR (chÆ°a cÃ³ biáº¿n)
"""

inputs = tokenizer(prompt, return_tensors="pt").to(model.device)
outputs = model.generate(**inputs, max_length=512)
result = tokenizer.decode(outputs[0], skip_special_tokens=True)

print(result)
```

### CÃ¡ch 2: Gradio Web UI (Dá»… HÆ¡n)

```bash
# Install
pip install gradio transformers peft torch

# Create gradio_app.py
cat > gradio_app.py << 'EOF'
import gradio as gr
from transformers import AutoModelForCausalLM, AutoTokenizer
from peft import PeftModel
import torch

# Load model
print("Loading model...")
base = AutoModelForCausalLM.from_pretrained(
    "Qwen/Qwen2.5-7B-Instruct",
    device_map="auto",
    torch_dtype=torch.float16
)
model = PeftModel.from_pretrained(base, "your-username/vietnamese-amr-mtup-7b")
tokenizer = AutoTokenizer.from_pretrained("your-username/vietnamese-amr-mtup-7b")
print("âœ… Model loaded!")

def parse_amr(sentence):
    prompt = f"""### NHIá»†M Vá»¤
Chuyá»ƒn Ä‘á»•i cÃ¢u tiáº¿ng Viá»‡t sang AMR (2 bÆ°á»›c)

### CÃ‚U Äáº¦U VÃ€O
{sentence}

### Káº¾T QUáº¢

## BÆ¯á»šC 1: Cáº¥u trÃºc AMR (chÆ°a cÃ³ biáº¿n)
"""
    inputs = tokenizer(prompt, return_tensors="pt").to(model.device)
    outputs = model.generate(**inputs, max_length=512)
    result = tokenizer.decode(outputs[0], skip_special_tokens=True)

    # Extract AMR
    if "AMR hoÃ n chá»‰nh:" in result:
        return result.split("AMR hoÃ n chá»‰nh:")[-1].strip()
    return result

demo = gr.Interface(
    fn=parse_amr,
    inputs=gr.Textbox(label="Vietnamese Sentence", lines=2),
    outputs=gr.Textbox(label="AMR Output", lines=10),
    title="Vietnamese AMR Parser",
    examples=[
        "TÃ´i yÃªu Viá»‡t Nam",
        "CÃ´ giÃ¡o Ä‘ang dáº¡y há»c sinh",
        "Anh áº¥y muá»‘n mua má»™t chiáº¿c xe má»›i"
    ]
)

demo.launch()
EOF

# Run
python3 gradio_app.py
# Opens at http://localhost:7860
```

## ðŸ” Troubleshooting

### Lá»—i: "HF_TOKEN not set"
```bash
# Check .env file exists
ls -la .env

# Check content
cat .env

# Fix: Make sure .env has your token
nano .env
```

### Lá»—i: "Model not found"
```bash
# Train model first!
python3 train_mtup.py --use-case best_accuracy

# Check model exists
ls outputs/models/mtup_two_task_7b/
```

### Lá»—i: "Permission denied"
```bash
# Token needs write permission
# Go to HF settings â†’ Tokens â†’ Regenerate with "write" permission
```

## ðŸ“Š Complete Workflow

```
DAY 1 - SERVER
â”œâ”€â”€ Train MTUP (4-6h)
â”‚   python3 train_mtup.py --use-case best_accuracy
â”‚
â”œâ”€â”€ Setup .env (2 min)
â”‚   cp .env.example .env
â”‚   nano .env  # Add HF_TOKEN
â”‚
â””â”€â”€ Push to HF (2-3 min)
    python3 push_to_hf_simple.py --model-type mtup

DAY 2 - SERVER
â”œâ”€â”€ Train Baseline (4-6h)
â”‚   python3 train_baseline.py
â”‚
â””â”€â”€ Push to HF (2-3 min)
    python3 push_to_hf_simple.py --model-type baseline

DAY 3 - LOCAL
â”œâ”€â”€ Install deps
â”‚   pip install transformers peft torch gradio
â”‚
â”œâ”€â”€ Create gradio_app.py
â”‚   # See example above
â”‚
â””â”€â”€ Run API
    python3 gradio_app.py
    # Open http://localhost:7860 âœ…
```

## ðŸŽ¯ Summary

**Question**: LÃ m sao push model lÃªn HF dá»… nháº¥t?

**Answer**: 3 bÆ°á»›c:
1. âœ… Láº¥y HF token (1 láº§n)
2. âœ… Edit .env file (1 láº§n)
3. âœ… Run `python3 push_to_hf_simple.py --model-type mtup`

**Time**: 2-3 phÃºt Ä‘á»ƒ push, 1-2 phÃºt Ä‘á»ƒ download vá» local láº§n Ä‘áº§u

**Result**: Model dÃ¹ng Ä‘Æ°á»£c á»Ÿ local báº±ng 1 dÃ²ng code:
```python
model = PeftModel.from_pretrained(base, "your-username/vietnamese-amr-mtup-7b")
```

---

**Cá»±c ká»³ Ä‘Æ¡n giáº£n!** ðŸš€
