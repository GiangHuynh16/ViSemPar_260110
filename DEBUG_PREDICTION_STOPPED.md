# üîç Debug: Prediction Process Stopped

## V·∫•n ƒë·ªÅ / Problem

Prediction process ƒë√£ d·ª´ng l·∫°i khi ƒëang ch·∫°y tr√™n server.

## C√°c b∆∞·ªõc ki·ªÉm tra / Debugging Steps

### 1. Ki·ªÉm tra process c√≥ c√≤n ch·∫°y kh√¥ng

```bash
ssh islabworker2@islab-server2

cd /mnt/nghiepth/giangha/visempar/ViSemPar_new1

# Check if still running
ps aux | grep predict_mtup_fixed.py
```

**N·∫øu c√≤n ch·∫°y:**
- Process v·∫´n ƒëang ho·∫°t ƒë·ªông, ch·ªâ l√† ch·∫≠m
- ƒê·ª£i th√™m (inference takes ~1 hour for 150 sentences)

**N·∫øu kh√¥ng ch·∫°y n·ªØa:**
- Process ƒë√£ crash ho·∫∑c k·∫øt th√∫c
- Ti·∫øp t·ª•c b∆∞·ªõc 2

---

### 2. Ki·ªÉm tra file output c√≥ ƒë∆∞·ª£c t·∫°o kh√¥ng

```bash
ls -lh evaluation_results/mtup_predictions_FIXED.txt

# Count predictions
wc -l evaluation_results/mtup_predictions_FIXED.txt

# View last few predictions
tail -50 evaluation_results/mtup_predictions_FIXED.txt
```

**N·∫øu file t·ªìn t·∫°i:**
- Check xem c√≥ bao nhi√™u predictions ƒë√£ ƒë∆∞·ª£c t·∫°o
- Expected: 150 AMRs (separated by blank lines)

**N·∫øu file kh√¥ng t·ªìn t·∫°i ho·∫∑c tr·ªëng:**
- Prediction crashed tr∆∞·ªõc khi save
- Ti·∫øp t·ª•c b∆∞·ªõc 3

---

### 3. Ki·ªÉm tra l·ªói trong stdout/stderr

N·∫øu b·∫°n ch·∫°y command trong screen/tmux:

```bash
# If using screen
screen -r  # Resume screen session

# If using tmux
tmux attach  # Resume tmux session
```

N·∫øu ch·∫°y tr·ª±c ti·∫øp, check terminal output ƒë·ªÉ t√¨m error message.

**Common errors:**

**A. CUDA OOM (Out of Memory)**
```
RuntimeError: CUDA out of memory
```

**Gi·∫£i ph√°p:**
```bash
# Use smaller batch or reduce max_new_tokens
python3 predict_mtup_fixed.py \
    --model outputs/mtup_fixed_20260104_082506/checkpoint-148 \
    --test-file data/public_test.txt \
    --output evaluation_results/mtup_predictions_FIXED.txt \
    --batch-size 1 \
    --verbose
```

**B. Hung on specific sentence**

Model generation stuck on m·ªôt c√¢u c·ª• th·ªÉ.

**Gi·∫£i ph√°p:** Add timeout
```python
# In predict_mtup_fixed.py, add timeout to generate():
with torch.no_grad():
    outputs = model.generate(
        **inputs,
        max_new_tokens=512,
        num_beams=1,
        do_sample=False,
        timeout=60.0  # 60 second timeout
    )
```

**C. Extraction error**

Warning v·ªÅ invalid AMR v√† process crash.

**Gi·∫£i ph√°p:** Predictions v·∫´n n√™n ƒë∆∞·ª£c save ngay c·∫£ khi invalid. Check code.

---

### 4. Ki·ªÉm tra sentence n√†o g√¢y l·ªói

```bash
# Check how many sentences processed
grep -c "Processing sentence" <logfile_if_exists>

# Or check output file
python3 << 'EOF'
with open('evaluation_results/mtup_predictions_FIXED.txt', 'r') as f:
    content = f.read()
    preds = content.strip().split('\n\n')
    print(f"Predictions generated: {len(preds)}")
    print(f"Expected: 150")

with open('data/public_test.txt', 'r') as f:
    sentences = [line.strip() for line in f if line.strip()]
    print(f"Total sentences: {len(sentences)}")

print(f"\nStopped at sentence: {len(preds) + 1}")
EOF
```

---

## Gi·∫£i ph√°p / Solutions

### Solution 1: Restart v·ªõi verbose logging

```bash
cd /mnt/nghiepth/giangha/visempar/ViSemPar_new1

python3 predict_mtup_fixed.py \
    --model outputs/mtup_fixed_20260104_082506/checkpoint-148 \
    --test-file data/public_test.txt \
    --output evaluation_results/mtup_predictions_FIXED.txt \
    --verbose 2>&1 | tee prediction.log
```

ƒêi·ªÅu n√†y s·∫Ω:
- Print m·ªçi b∆∞·ªõc processing
- Save log to `prediction.log`
- D·ªÖ debug n·∫øu crash l·∫°i

---

### Solution 2: Test v·ªõi 10 sentences tr∆∞·ªõc

```bash
# Create small test file
head -10 data/public_test.txt > data/test_small.txt

# Test prediction
python3 predict_mtup_fixed.py \
    --model outputs/mtup_fixed_20260104_082506/checkpoint-148 \
    --test-file data/test_small.txt \
    --output evaluation_results/mtup_test_small.txt \
    --verbose
```

N·∫øu 10 sentences work ‚Üí Problem l√† timeout/memory v·ªõi full dataset

N·∫øu 10 sentences c≈©ng crash ‚Üí Problem l√† model/code logic

---

### Solution 3: Resume t·ª´ checkpoint (n·∫øu c√≥ partial output)

```python
# Add to predict_mtup_fixed.py
# Check if output file exists and skip processed sentences

if os.path.exists(args.output):
    with open(args.output, 'r') as f:
        existing_preds = f.read().strip().split('\n\n')
        skip_count = len(existing_preds)
        print(f"Found {skip_count} existing predictions, resuming...")
else:
    skip_count = 0

# Then in loop:
for i, sentence in enumerate(sentences):
    if i < skip_count:
        continue  # Skip already processed
    # ... rest of prediction
```

---

### Solution 4: Generate in smaller batches v·ªõi explicit save

```python
# Modify to save after every N predictions
SAVE_INTERVAL = 10

predictions = []
for i, sentence in enumerate(sentences):
    pred = self.predict(sentence)
    predictions.append(pred)

    # Save checkpoint every 10 predictions
    if (i + 1) % SAVE_INTERVAL == 0:
        with open(args.output, 'w') as f:
            f.write('\n\n'.join(predictions))
        print(f"Saved checkpoint at {i+1} predictions")

# Final save
with open(args.output, 'w') as f:
    f.write('\n\n'.join(predictions))
```

---

## Quick Fix - Run ngay b√¢y gi·ªù

**Option A: N·∫øu b·∫°n mu·ªën ch·∫°y l·∫°i ngay (recommended)**

```bash
ssh islabworker2@islab-server2
cd /mnt/nghiepth/giangha/visempar/ViSemPar_new1

# Test small first (5 minutes)
head -10 data/public_test.txt > data/test_small.txt

python3 predict_mtup_fixed.py \
    --model outputs/mtup_fixed_20260104_082506/checkpoint-148 \
    --test-file data/test_small.txt \
    --output evaluation_results/mtup_test_small.txt \
    --verbose

# If successful, run full (1 hour)
python3 predict_mtup_fixed.py \
    --model outputs/mtup_fixed_20260104_082506/checkpoint-148 \
    --test-file data/public_test.txt \
    --output evaluation_results/mtup_predictions_FIXED.txt \
    --verbose 2>&1 | tee prediction.log
```

**Option B: N·∫øu b·∫°n mu·ªën t√¥i debug code tr∆∞·ªõc**

Tell me:
1. Error message cu·ªëi c√πng b·∫°n th·∫•y (n·∫øu c√≥)
2. File `evaluation_results/mtup_predictions_FIXED.txt` c√≥ t·ªìn t·∫°i kh√¥ng?
3. N·∫øu c√≥, c√≥ bao nhi√™u predictions? (`wc -l evaluation_results/mtup_predictions_FIXED.txt`)

---

## Expected timeline

- **Small test (10 sentences):** ~2-3 minutes
- **Full test (150 sentences):** ~30-60 minutes (2-stage generation is slower)
- **SMATCH calculation:** ~5 minutes

---

## What to expect when successful

```
Processing sentence 1/150: T√¥i nh·ªõ l·ªùi...
  Stage 1: (nh·ªõ :pivot (t√¥i) :theme (l·ªùi...))
  Stage 2: (n / nh·ªõ :pivot (t / t√¥i) :theme (l / l·ªùi...))
  ‚úì Valid AMR

Processing sentence 2/150: ...
...

Processing sentence 150/150: ...
  ‚úì Valid AMR

================================================================================
PREDICTION COMPLETE
================================================================================

Total predictions: 150
Valid AMRs: 137 (91.3%)
Invalid AMRs: 13 (8.7%)

Saved to: evaluation_results/mtup_predictions_FIXED.txt
```

Sau ƒë√≥:

```bash
# Calculate SMATCH
python3 filter_valid_amrs.py \
    --predictions evaluation_results/mtup_predictions_FIXED.txt \
    --ground-truth data/public_test_ground_truth.txt \
    --output-pred evaluation_results/mtup_valid.txt \
    --output-gold evaluation_results/gold_valid.txt

python -m smatch -f \
    evaluation_results/mtup_valid.txt \
    evaluation_results/gold_valid.txt \
    --significant 4
```

**Expected F1:** 0.50-0.55 (hypothesis: better than Baseline's 0.47)

---

## H√£y cho t√¥i bi·∫øt / Please tell me:

1. **B·∫°n c√≥ th·∫•y error message g√¨ kh√¥ng?** (Any error messages?)
2. **File output c√≥ t·ªìn t·∫°i kh√¥ng?** (Does output file exist?)
3. **B·∫°n mu·ªën t√¥i s·ª≠a code hay b·∫°n s·∫Ω ch·∫°y l·∫°i?** (Want me to fix code or will you rerun?)
